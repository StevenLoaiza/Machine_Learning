{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Supervised-Learning\" data-toc-modified-id=\"Supervised-Learning-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Supervised Learning</a></span><ul class=\"toc-item\"><li><span><a href=\"#Linear-Regression\" data-toc-modified-id=\"Linear-Regression-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Linear Regression</a></span><ul class=\"toc-item\"><li><span><a href=\"#Gathering-Data\" data-toc-modified-id=\"Gathering-Data-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Gathering Data</a></span></li><li><span><a href=\"#Data-Preparation\" data-toc-modified-id=\"Data-Preparation-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Data Preparation</a></span></li><li><span><a href=\"#Choosing-a-Model\" data-toc-modified-id=\"Choosing-a-Model-2.1.3\"><span class=\"toc-item-num\">2.1.3&nbsp;&nbsp;</span>Choosing a Model</a></span></li><li><span><a href=\"#Training\" data-toc-modified-id=\"Training-2.1.4\"><span class=\"toc-item-num\">2.1.4&nbsp;&nbsp;</span>Training</a></span></li><li><span><a href=\"#Evaluation\" data-toc-modified-id=\"Evaluation-2.1.5\"><span class=\"toc-item-num\">2.1.5&nbsp;&nbsp;</span>Evaluation</a></span></li><li><span><a href=\"#Visualization\" data-toc-modified-id=\"Visualization-2.1.6\"><span class=\"toc-item-num\">2.1.6&nbsp;&nbsp;</span>Visualization</a></span></li><li><span><a href=\"#Parameter-Tuning\" data-toc-modified-id=\"Parameter-Tuning-2.1.7\"><span class=\"toc-item-num\">2.1.7&nbsp;&nbsp;</span>Parameter Tuning</a></span></li></ul></li><li><span><a href=\"#Exercise\" data-toc-modified-id=\"Exercise-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Exercise</a></span></li><li><span><a href=\"#K---Nearest-Neighborhood-Method\" data-toc-modified-id=\"K---Nearest-Neighborhood-Method-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>K - Nearest Neighborhood Method</a></span><ul class=\"toc-item\"><li><span><a href=\"#KNN-Algorithm-Pseudocode:\" data-toc-modified-id=\"KNN-Algorithm-Pseudocode:-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>KNN Algorithm Pseudocode:</a></span></li><li><span><a href=\"#Gathering-Data\" data-toc-modified-id=\"Gathering-Data-2.3.2\"><span class=\"toc-item-num\">2.3.2&nbsp;&nbsp;</span>Gathering Data</a></span></li><li><span><a href=\"#Data-Preperation\" data-toc-modified-id=\"Data-Preperation-2.3.3\"><span class=\"toc-item-num\">2.3.3&nbsp;&nbsp;</span>Data Preperation</a></span></li><li><span><a href=\"#Choose-Model-and-Training\" data-toc-modified-id=\"Choose-Model-and-Training-2.3.4\"><span class=\"toc-item-num\">2.3.4&nbsp;&nbsp;</span>Choose Model and Training</a></span></li><li><span><a href=\"#Evaluation\" data-toc-modified-id=\"Evaluation-2.3.5\"><span class=\"toc-item-num\">2.3.5&nbsp;&nbsp;</span>Evaluation</a></span></li><li><span><a href=\"#Parameter-Tuning\" data-toc-modified-id=\"Parameter-Tuning-2.3.6\"><span class=\"toc-item-num\">2.3.6&nbsp;&nbsp;</span>Parameter Tuning</a></span></li></ul></li><li><span><a href=\"#Additional-Notes:\" data-toc-modified-id=\"Additional-Notes:-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Additional Notes:</a></span></li></ul></li><li><span><a href=\"#Conclusion\" data-toc-modified-id=\"Conclusion-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Conclusion</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "\n",
    "Algorithms are the basis of solving problems with a computer. We need a set of direction to tell the computer to run, in order to turn input into output. For example, we can develop an algorithm to trim observations\n",
    "with values of NA. We would ask the computer to take a dataset as an input, look at the rows of a certain column and if that column returns NA, it would remove the column.\n",
    "\n",
    "There may be some problem, that an algorithm does not exist, or would be very difficult to create. In other words, we are unable to transform the input easily into an output. Fortunately, if we have a large dataset we can us the computer (machine) to extract the algorithm for us. We do not need to know the data generating process for the data, but we can use patterns from the data to provide a useful approximation.\n",
    "\n",
    "This approximation can later be used to make predictions, assuming that the pattern would continue on unobserved data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning \n",
    "\n",
    "Using inputs (independent variables) to predict the values of the outputs (dependent variable) is called **supervised learning**.\n",
    "\n",
    "Our dependent variable can be categorical(qualitative) or numerical (continuous, or discrete). Some of the terminology in machine learning(ML) is that **regression** are for quantitaive outputs and **classification** are for qualitative outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression \n",
    "The linear model is the simplest form of predicting values. Here we are stating that the independent variables\n",
    "affect the dependent variable linearly.\n",
    "\n",
    "\\begin{equation*}\n",
    "\\hat{Y} = \\hat{\\beta}_0 + \\sum^{J}_{j=1} x_j \\hat{\\beta}_j=X^T \\hat{\\beta}\n",
    "\\end{equation*}\n",
    "\n",
    "The intercept is known as the bias in ML, while the other betas are the corresponding coefficients for the independent varibles. The betas represent the partial derivative with respect to the independent variable.\n",
    "\n",
    "Lets begin our process of Machine Learning:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gathering Data\n",
    "\n",
    "We begin by setting a seed, the number inside the parenthesis is arbitrary. The reason we set a seed is\n",
    "so that we obtain the same random variables when ever we rerun the code, thus getting the same results.\n",
    "We will sample one thousand observation from the uniform distribution with different ranges. Then we will\n",
    "produce an output. Observe that our linear model intercept is set to zero, and we have defined our betas.\n",
    "In essence this is the population linear model, the true data generating process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       y                  x1                  x2          \n",
       " Min.   :0.009879   Min.   :0.0009545   Min.   :0.002781  \n",
       " 1st Qu.:0.272609   1st Qu.:0.1806411   1st Qu.:0.244862  \n",
       " Median :0.390394   Median :0.3727318   Median :0.508171  \n",
       " Mean   :0.383089   Mean   :0.3614634   Mean   :0.505893  \n",
       " 3rd Qu.:0.495837   3rd Qu.:0.5339685   3rd Qu.:0.762016  \n",
       " Max.   :0.737228   Max.   :0.6996580   Max.   :0.998414  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#------------------------------------------------\n",
    "# Gather the Data\n",
    "#------------------------------------------------\n",
    "set.seed(501)\n",
    "\n",
    "n=1000\n",
    "x1<-runif(n,min=0,max=.7)\n",
    "x2<-runif(n,min=0,max=1)\n",
    "y<-0.5*x1+0.4*x2 \n",
    "\n",
    "data<-as.data.frame(cbind(y,x1,x2))\n",
    "summary(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Output values range from ~0.01 to ~0.74 with a mean of ~0.38, approximately. One thing to notice is\n",
    "that the independent variables are within the same range, by construction. There may be time when we will\n",
    "have to normalize the data, that way the magnitude of one variable does not over power the predictiveness\n",
    "of ML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "Lets create a rule for our output. From the summary of the data we say that the mean of the output data\n",
    "was about 0.4, therefore we will classify the output as such: values greater than 0.4 are red, otherwise they\n",
    "are blue. Since we are using a linear model, we will code the outputs as a 0-1 dummary variable, 1=blue.\n",
    "\n",
    "Using the mean will allow our data to have even amount of reds and blues, which again will help avoid\n",
    "having one of the outputs outweight the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Red</th><th scope=col>Blue</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0  </td><td>470</td></tr>\n",
       "\t<tr><td>1  </td><td>530</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       " Red & Blue\\\\\n",
       "\\hline\n",
       "\t 0   & 470\\\\\n",
       "\t 1   & 530\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| Red | Blue |\n",
       "|---|---|\n",
       "| 0   | 470 |\n",
       "| 1   | 530 |\n",
       "\n"
      ],
      "text/plain": [
       "  Red Blue\n",
       "1 0   470 \n",
       "2 1   530 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#------------------------------------------------\n",
    "# Prepare Data\n",
    "#------------------------------------------------\n",
    "Recode<- function(y)\n",
    "{\n",
    "  \n",
    "  if(y>.4)\n",
    "  {y<-0}\n",
    "  \n",
    "  else{y<-1}\n",
    "}\n",
    "#apply function above to each row\n",
    "y_recode=as.data.frame(sapply(y,Recode))\n",
    "names(y_recode)<-c('yrecode')\n",
    "data<-cbind(data,y_recode)\n",
    "\n",
    "#create a table and rename col\n",
    "Freqtable<-data.frame(table(data$yrecode))\n",
    "colnames(Freqtable)<-c(\"Red\",\"Blue\")\n",
    "#print\n",
    "Freqtable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing a Model\n",
    "Since we know what the actual model is , we will choose a linear model. Our initial guess for our model will\n",
    "be :\n",
    "\n",
    "\\begin{equation*}\n",
    "Y=0.5X_1+0.4X_2\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training \n",
    "<a id=\"train\"></a>\n",
    "Given our specification of the model above, we will use it on our training Data and get our output. This is\n",
    "simple just specify the columns for each of the independent variables, and then recode the output values as\n",
    "we did earlier. Try it out for youself before seeing the code in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "This is where the bulk of the ML starts. We need to evaluate how well our initial model did against the\n",
    "training data. We are able to evaluate the preformance because we know the actual values of Y.\n",
    "In order to create a ML process , we will need to update our parameters given some Loss value. Loss\n",
    "would be the calculation of how many output variables we predicted incorrectly. Below I will write some ad\n",
    "psuedo code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Example:</b> \n",
    "    function(Initial Values){ <br>\n",
    "parameters= Initial Values <br>\n",
    "RunModel(parameters) <br>\n",
    "if (LossValue gt epsilon) <br>\n",
    "{return Y} <br>\n",
    "else parameters<-updateValues}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we were to run this code it will give us the best predictive values,but it may take a very long time for\n",
    "us to get the LossValue below some threshold. Instead we will initialize the number of times we want it to\n",
    "run the iteration.\n",
    "First we will see how well our first guess, or initial values do in our linear model. With our initial guess\n",
    "we have predicted the correct values 77% of the time. Now lets build our ML model to iterate over different\n",
    "values of coe\u001e",
    "cients and find the one with the best accuracy.\n",
    "You will note that I have defined the size of the Accuracy and ypred vector prior to the loop, this is to\n",
    "save on speed and not have the vector changing size as the loop continues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'The Accuracy is: 77.3 percent'"
      ],
      "text/latex": [
       "'The Accuracy is: 77.3 percent'"
      ],
      "text/markdown": [
       "'The Accuracy is: 77.3 percent'"
      ],
      "text/plain": [
       "[1] \"The Accuracy is: 77.3 percent\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#-------------------------\n",
    "#Training\n",
    "#-------------------------\n",
    "n=4\n",
    "intb1<-0.0\n",
    "intb2<-0.8\n",
    "Accuracy<-rep(0,n)\n",
    "ypred<-as.data.frame(matrix(0,nrow=nrow(data),ncol=n))\n",
    "\n",
    "b1<-intb1\n",
    "b2<-intb2\n",
    "\n",
    "ypred[,1]<-b1*data$x1+b2*data$x2\n",
    "#recode the predictions to a binary classification\n",
    "ypred[,1]<-as.data.frame(sapply(ypred[,1],Recode))\n",
    "data$ypred<-ypred[,1]\n",
    "Accuracy[1]<-mean(data$yrecode==ypred[,1])\n",
    "sprintf(\"The Accuracy is: %g percent\",Accuracy[1]*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will build our ML model. Let create a vector of the betas, called B, and also a vector or values\n",
    "that we will call A and C. The vector A and C will be used to update the values of B. The values in A and\n",
    "C were chosen arbitrarily. Since we know that the values of the original Y's before the tranformation are\n",
    "below 1, then the change in our beta should not be large and should also be below 1. Therefore we use two\n",
    "assumptions that in order to increase the accuracy either both betas increase or one does with the other\n",
    "decreases.\n",
    "\n",
    "Now for our function, it takes our initial guesses as inputs, then it transforms them starting with assumption\n",
    "A, again arbitrary choice. We begin our loop and calculate our new prediciton and its accuracy<a href=\"#ref1\">[1]</a>. If\n",
    "our new accuracy parameter is larger than the previous accuracy parameter from our training section then\n",
    "update using assumption A. Once the loop is done, we check which entry in our vector is the one with the\n",
    "highest accuracy and then we return the value as well as the corresponding ypred vector. Finally we run the\n",
    "code and view the data side by side , with our True Y values and our first prediciton.\n",
    "\n",
    "<font size=\"1\"><a id=\"ref1\">[1]</a>Our for loop starts from i=2 because our vector ypred's first column is the prediction from section <a href=\"#train\">Training</a>.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'The Accuracy is: 79.1 Percent'"
      ],
      "text/latex": [
       "'The Accuracy is: 79.1 Percent'"
      ],
      "text/markdown": [
       "'The Accuracy is: 79.1 Percent'"
      ],
      "text/plain": [
       "[1] \"The Accuracy is: 79.1 Percent\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#initial values\n",
    "\n",
    "n<-4\n",
    "B<-rbind(intb1,intb2)\n",
    "A<-matrix(c(0.05,-0.1),nrow=2,ncol=1)\n",
    "C<-matrix(c(0.1,0.1),nrow=2,ncol=1)\n",
    "\n",
    "ML<-function(intb1,intb2){\n",
    "    B<-B+A\n",
    "    #number of iteration, to change the parameters\n",
    "    for(i in 2:n)\n",
    "    {\n",
    "        ypred[,i]<-B[1]*data$x1+B[2]*data$x2\n",
    "        # recode to a binary variable\n",
    "        ypred[,i]<-as.data.frame(sapply(ypred[,i],Recode))\n",
    "        Accuracy[i]<-mean(data$yrecode==ypred[,i])\n",
    "        \n",
    "        #condition if the new accuracy is better than the previous\n",
    "        #continue on the A path otherwise switch to C\n",
    "        if(Accuracy[i]>=Accuracy[i-1])\n",
    "            {B<-B+A\n",
    "            }else{B<-C+B}\n",
    "    #loop ends    \n",
    "    }\n",
    "    \n",
    "    #grab the position of the largest accuracy\n",
    "    position<-which.max(Accuracy)\n",
    "    #return the values\n",
    "    max_val<-Accuracy[position]\n",
    "    #print solution\n",
    "    solution<-c(ypred[,position],sprintf(\"The Accuracy is: %g Percent\", (max_val*100)))\n",
    "    #return the value\n",
    "    return(solution)\n",
    "}\n",
    "\n",
    "#save the results into parameter\n",
    "Lin.sol<-as.data.frame(ML(intb1,intb2))\n",
    "data$ypred1<-Lin.sol[1:nrow(data),1]\n",
    "\n",
    "#view\n",
    "as.character(Lin.sol[nrow(data)+1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "\n",
    "Lets visualize the data above. We are going to plot the datapoints with the decision that any $y > 0.4$ is going to be red. Thus $0.4 = g(x1; x2)$ is our decision boundary.\n",
    "\n",
    "\\begin{equation*}\n",
    "0.4 = g(x1; x2)= 0.5x_1+0.4x_2\n",
    "\\end{equation*}\n",
    "\n",
    "and solving for $x_2$:\n",
    "\n",
    "\\begin{equation*}\n",
    "x_2=1-\\frac{0.5}{0.4}x_1\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAaVBMVEUAAAAAv8QzMzNNTU1o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\nkIFkMhWQgWQyFdD/A/i85W7xm9rXAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "suppressWarnings(library(ggplot2))\n",
    "ggplot(data=test,aes(x1,x2))+\n",
    "geom_point(aes(color=as.factor(yrecode)))+\n",
    "labs(title=\"Linear Decision Boundary\",caption=\"some points are misclassfied at the boundary line.\")+\n",
    "scale_colour_discrete(name='binary variable')+\n",
    "theme(text=element_text(size=15))+\n",
    "#intercept (bounday - b0)/b2\n",
    "#slope -(b2/b1)\n",
    "geom_abline(intercept=1,slope=-(0.5/0.4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Tuning\n",
    "\n",
    "Our ML model from the previous section did pretty well, it was able to predict our training data set 81.9%\n",
    "of the time. But can we do any better?\n",
    "Lets go back to our intrductory course of Econometrics, where we use optimization to get the values of $\\beta$ by minimizing least squares.\n",
    "\n",
    "\\begin{equation*}\n",
    "argmin_{\\beta \\epsilon B} = \\sum_{i=1}^N (y_i - x_t^T \\beta)^2= (\\textbf{y-X}\\beta)^T(\\textbf{y-X}\\beta)\n",
    "\\end{equation*}\n",
    "if $X^TX$ is nonsingular, then the solution will be unique:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\hat{\\beta}=(\\textbf{X}^T\\textbf{X})^{-1}\\textbf{X}^T\\textbf{y}\n",
    "\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>x1</dt>\n",
       "\t\t<dd>0.5</dd>\n",
       "\t<dt>x2</dt>\n",
       "\t\t<dd>0.4</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[x1] 0.5\n",
       "\\item[x2] 0.4\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "x1\n",
       ":   0.5x2\n",
       ":   0.4\n",
       "\n"
      ],
      "text/plain": [
       " x1  x2 \n",
       "0.5 0.4 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'The Accuracy is: 100 percent'"
      ],
      "text/latex": [
       "'The Accuracy is: 100 percent'"
      ],
      "text/markdown": [
       "'The Accuracy is: 100 percent'"
      ],
      "text/plain": [
       "[1] \"The Accuracy is: 100 percent\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#-----------------\n",
    "#parameter tunning\n",
    "#-----------------\n",
    "library(MASS)\n",
    "#Linear Regression\n",
    "fit<-lm(y~x1+x2-1,data)\n",
    "fit$coefficients\n",
    "\n",
    "# Accuracy of the model\n",
    "b1<-fit$coefficients[1]\n",
    "b2<-fit$coefficients[2]\n",
    "\n",
    "y_hat<-b1*x1+b2*x2\n",
    "data_tune<-as.data.frame(cbind(y_recode,x1,x2))\n",
    "data_tune$pred_y<-sapply(y_hat,Recode)\n",
    "names(data_tune)<-c('True_y','X1','X2','Pred_y')\n",
    "\n",
    "sprintf(\"The Accuracy is: %g percent\",mean(data_tune$True_y==data_tune$Pred_y)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting accuracy is 100%. Why?\n",
    "\n",
    "Because we have all the information needed to accurately fit the model. In practice, we do not have all the features neccessary to fit a model. Therefore our linear regression will have some random error which represents other factors that impact the target variable ($y$) but that we are unable to account for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "Build a table showing the count of each value of Y and\n",
    "how well the prection did against it.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K - Nearest Neighborhood Method\n",
    "\n",
    "In its simplist form (classification), uses $x_i$ K Nearest Neighbors to vote on what $x_i$s label should be. If\n",
    "this were a quantitative output, it could be the mean of the K- Nearest Neighbors.\n",
    "For out example above which is quantitative, and the range of the independent variables are similar by\n",
    "choice, we can use the Euclidean distance for our algorithm. There are other methods to view the distance\n",
    "such as Manhattan and Minkowski. There is also the Hamming Distance for categorical variables.\n",
    "\\begin{equation*}\n",
    "Euclidean =\\sqrt{\\sum (qi-pi)2}\n",
    "\\end{equation*}\n",
    "Choosing k\n",
    "-Increasing k reduces variances, but increases the bias\n",
    "Lets assume our Y is a quantity. Therefore, we choose $\\hat{Y}$ such that:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\hat{Y}=\\frac{1}{k}\\sum_{x_i \\epsilon N-k(x)}y_i,\n",
    "\\end{equation*}\n",
    "\n",
    "The k- nearest neighbor fit $\\hat{Y}$ where $N_k(x)$ is the neighborhood of x which is defined by the k closest\n",
    "points in the training sample. The closeness is defined by the Euclidean distance above.\n",
    "For our example above which is defined as a dummy variable, where 1=\"Blue\" and 0=\"Red\" our  $\\hat{Y}$ is:\n",
    "\\begin{equation*}\n",
    "\\hat{Y}= \\frac{Blue \\sum_{x_i \\epsilon N-k(x)}y_i = \"Blue\" > \\sum_{x_i \\epsilon N-k(x)}y_i =\"Red\" }{Red \\space else} \n",
    "\\end{equation*}\n",
    "\n",
    "Some Cons of this method: To determine the nearest neighbor of a new point x, must compute the\n",
    "distance to all m training examples. Runtime performance is slow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Algorithm Pseudocode:\n",
    "\n",
    "1. Calculate $d(x,x_i) \\forall i \\space \\epsilon \\space (1,2...,n);$ where d denotes the Euclidean distance between points.\n",
    "2. Sort the distrances in non-descending order\n",
    "3. Let $k$ be a positive integer, take the first k distances from the list in step 2.\n",
    "4. Find those $k$- points corresponding to these k-distances.\n",
    "5. Let $k_i$ denote the number of points belonging to the $i^{th}$ class among k points.\n",
    "6. if $k_i>k_j \\space \\forall i \\ne j$ then put x in class i."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gathering Data\n",
    "\n",
    "This will be exactly the same as section 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preperation\n",
    "The only difference from section one is that we are going to split the data to have a test and training model.\n",
    "The split we will use is one-third is our test data and the other will be the train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Test Data Split \n",
    "\n",
    "set.seed(130)\n",
    "ind<-sample(2,nrow(data),replace=TRUE,prob=c(0.67,0.33))\n",
    "train<-data[ind==1,2:3]\n",
    "test2<-data[ind==2,2:3]\n",
    "\n",
    "test2.results<-data[ind==2,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose Model and Training\n",
    "\n",
    "We will choose the KNN model, but instead of using the imbedded Knn function we will build it from scratch.\n",
    "Suppose we have the following data. The one on the left represents our train data, and the right our test\n",
    "data.\n",
    "\n",
    "| x<sub>1</sub>   |      g<sub>1</sub>     |  |  x<sub>2</sub> | g<sub>2</sub>|\n",
    "|----------|:-------------:|   |:------:|-------:|\n",
    "| x<sub>11</sub> |  g<sub>11</sub> |       | x<sub>21</sub> |g<sub>21</sub>|\n",
    "| x<sub>12</sub> |  g<sub>12</sub>|      |   x<sub>22</sub> |g<sub>22</sub>|\n",
    "|x<sub>13</sub> |  g<sub>13</sub>||   |||\n",
    "\n",
    "From our function of Euclidean distance we want the following outcomes, Dist_1 is the list of distance\n",
    "of our first obsevation in our test data against all the points in the train data, conversely Dist_2 is for the second observation.\n",
    "<table>\n",
    "      <col width=\"250\">\n",
    "  <col width=\"250\">\n",
    "<tr>\n",
    "<th>Distance 1</th>\n",
    "<th>Distance 2</th>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\\begin{equation*}d_{11}=\\sqrt{(x_{21}-x{11})^2+(g_{21}-g{11})^2}\\end{equation*}</td>\n",
    "<td>\\begin{equation*}d_{21}=\\sqrt{(x_{22}-x{11})^2+(g_{22}-g{11})^2}\\end{equation*}</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td> \\begin{equation*}d_{12}=\\sqrt{(x_{21}-x{12})^2+(g_{21}-g{12})^2}\\end{equation*}</td>\n",
    "<td>\\begin{equation*}d_{22}=\\sqrt{(x_{22}-x{12})^2+(g_{22}-g{12})^2}\\end{equation*} </td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\\begin{equation*}d_{13}=\\sqrt{(x_{21}-x{13})^2+(g_{21}-g{13})^2}\\end{equation*}</td>\n",
    "<td>\\begin{equation*}d_{23}=\\sqrt{(x_{22}-x{13})^2+(g_{22}-g{13})^2}\\end{equation*}</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "Lets Begin our code, first lets start with the first observation $i = 1$ and calculate the distance for all the rows of our train table, j $\\epsilon$(1 :# of rows of train data).\n",
    "\n",
    "We begin our for loop with observation $j= 1$ which corresponds to $d_{11}$. The second line is taking the $i^{th}$\n",
    "and $j^{th}$ row of our test and trian table, explicity rows 1. Then the operation is a entry by entry operation.\n",
    "In essence test2\\[1, \\] would return \\[$x_{21}g_{21}$\\] and similarly for train\\[1, \\]. Now c would contain \\[$(x_{21} - x_{11})^2(g_{21} - g_{11})^2$\\] as a vector. Finally the last line just extracts the two values and sums them to finish the\n",
    "Euclidean Distance formula. This would be iterated until the entire column Dist_1 is filled.\n",
    "\n",
    "Next we will order our distance in non-decresing order and take the k closest points. After the k closest\n",
    "points are obtained, we will average the points, since it is just a grid of zeros or ones. Next we de\u001c",
    "ne a rule for prediction, the basic rule is that if the average is over 50% then pred=1, since that means that there were more values of 1 than 0, otherwise set pred=0. Ok now we just predicted the first observation of our test data.\n",
    "\n",
    "<table>\n",
    "      <col width=\"250\">\n",
    "<tr>\n",
    "<th>Pred</th>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>Pred_1=result</td>\n",
    "    </tr>\n",
    "<tr>\n",
    "<td>Pred_2</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "The final step is to do this for the rest of the rows of the test data. Hence our for loop above, will be\n",
    "nested in another for loop for all the $i \\space \\epsilon \\space$(1 :# of rows of test data). Our complete Knn prediction function looks like this and we will also time how long it takes for our code to run through our test and train set, it took the computer 404 seconds to execute the command. The reason it took about ~7 mins\n",
    "is because for-loops are inefficient and the loop is \\[running number of row(test2) $\\cdot$ number of rows(train)\\] calculations , not including the time to sort data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   user  system elapsed \n",
       " 404.57    0.64  410.53 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#------------------------------------------------\n",
    "# Choose Model and Training\n",
    "#------------------------------------------------\n",
    "#------------------------\n",
    "# Build KNN From Scratch\n",
    "#------------------------\n",
    "\n",
    "#defining variables before hand\n",
    "\n",
    "pred<-as.data.frame(matrix(0,nrow=nrow(test2),1))\n",
    "eu_dist<-as.data.frame(matrix(0,nrow=nrow(train),1)) \n",
    "e<-eu_dist\n",
    "eu_dist<-cbind(eu_dist,data[ind==1,4])\n",
    "k<-3\n",
    "\n",
    "knn_predict <- function(test2,train,k){\n",
    "  \n",
    "  #Loop 1\n",
    "  \n",
    "  for(i in (1:nrow(test2))){\n",
    "    \n",
    "    \n",
    "    #Loop 2\n",
    "    for(j in (1:nrow(train))){\n",
    "      # Perform Euclidean Dist\n",
    "      c<-(test2[i,]-train[j,])^2\n",
    "      eu_dist[j,1]<-c[1]+c[2]\n",
    "    }\n",
    "    #order distance in non-decreasing order\n",
    "    e<-eu_dist\n",
    "    e<-e[order(e$V1),]\n",
    "    #lets take the k closest points\n",
    "    e<-e[1:k,2]\n",
    "    # lets take the average of these points\n",
    "    s<-sum(e)/k\n",
    "    #rule for prediction\n",
    "    if(s>0.5)\n",
    "    {pred[i,]<-1 \n",
    "    }else {pred[i,]<-0}\n",
    "  }\n",
    "  return(pred)\n",
    "}\n",
    "\n",
    "#Start Clock\n",
    "ptm<-proc.time()\n",
    "# Run Code\n",
    "Y_Pred<-knn_predict(test2,train,k)\n",
    "#Stop Clock\n",
    "proc.time()-ptm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "Let check how well our model will predict out test set. We see that we are able to predict 97% of the output correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "97.1014492753623"
      ],
      "text/latex": [
       "97.1014492753623"
      ],
      "text/markdown": [
       "97.1014492753623"
      ],
      "text/plain": [
       "[1] 97.10145"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#------------------------------------------------\n",
    "# Evaluation\n",
    "#------------------------------------------------\n",
    "test2.results<-sapply(test2.results, function(x){Recode(x)})\n",
    "Y_Actu<-as.data.frame(test2.results)\n",
    "mean(Y_Pred == Y_Actu)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Tuning\n",
    "\n",
    "Below we optimization the computational time (we will only use one loop instead, sweep() helps us avoid a loop), Notice that using the same data it only took 1.92 seconds to solve, and we checked that the results are the same, which they are!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   user  system elapsed \n",
       "   1.08    0.00    1.17 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "100"
      ],
      "text/latex": [
       "100"
      ],
      "text/markdown": [
       "100"
      ],
      "text/plain": [
       "[1] 100"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#defining variables before hand\n",
    "\n",
    "pred<-as.data.frame(matrix(0,nrow=nrow(test2),1))\n",
    "e_dist<-as.data.frame(matrix(0,nrow=nrow(train),1)) \n",
    "e<-e_dist\n",
    "e_dist<-cbind(e_dist,data[ind==1,4])\n",
    "k<-3\n",
    "# we will transpose the data in order to run it in the function sweep()\n",
    "test3<-t(test2)\n",
    "#---------------\n",
    "\n",
    "knn_predict2<-function(test3,train,k){\n",
    "  for (i in (1:nrow(test2))){\n",
    "    #Euclidean Dist\n",
    "    \n",
    "    #sweep with subtract the ith column of test3 (which is just the ith row of test2) \n",
    "    # from all rows in train data set\n",
    "    subtrct<-sweep(-train[,],2,-test3[,i])\n",
    "    # next we will square element by element\n",
    "    subtrct<-subtrct^2\n",
    "    # then we add each value as we did for line 69 above\n",
    "    e_dist[,1]<-as.data.frame(subtrct[,1]+subtrct[,2])\n",
    "    e<-e_dist\n",
    "    #order\n",
    "    colnames(e)[1]<-\"V1\"\n",
    "    e<-e[order(e$V1),]\n",
    "    #lets take the k closest points\n",
    "    e<-e[1:k,2]\n",
    "    # lets take the average of these points\n",
    "    s<-sum(e)/k\n",
    "    #rule for prediction\n",
    "    if(s>0.5)\n",
    "    {pred[i,]<-1 \n",
    "    }else {pred[i,]<-0}\n",
    "  }\n",
    "  return(pred)\n",
    "}\n",
    "\n",
    "#Start Clock\n",
    "ptm<-proc.time()\n",
    "# Run Code\n",
    "Y_Pred2<-knn_predict2(test3,train,k)\n",
    "#Stop Clock\n",
    "proc.time()-ptm\n",
    "\n",
    "#check if the results are the same as the first formula\n",
    "mean(Y_Pred==Y_Pred2)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Notes:\n",
    "\n",
    "There are built in function that will perform our KNN algorithm, you can install.package(\"class\") for the\n",
    "knn() function.\n",
    "There is also a package called \"caret\" which hold an abundance of ML models. Check it out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In this post we have introduced the concept of supervised learning, and worked on two techniques (Linear Regression and KNN). Keep in mind that these are no the only supervised learning technique. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
