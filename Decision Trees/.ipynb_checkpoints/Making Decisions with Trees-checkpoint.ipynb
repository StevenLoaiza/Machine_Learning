{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\"><b>Making Decisions with Trees</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction <a id=\"intro\"></a>\n",
    "\n",
    "We make decisions in our lives everyday. Although we make decisions so often, we may not stop to think exactly how we made them.\n",
    "\n",
    "Let's think about a decision many of us have come across: **Going to Work**. Without realizing it, we tend to ask ourselves sequential questions, that lead us to our decision. Should I go to work? Do I have enough sick time? etc. One question leads to another, forming what looks like a tree, until we get to our final decision.\n",
    "\n",
    "Decision trees are a simple yet powerful tool in predictive modeling. \n",
    "\n",
    "Unlike other predictive models, such as neural networks, we are able to decipher the inner working of a decision trees. In other words, they are easier to interpret. We can trace back the decisions that led to a particular prediction.\n",
    "\n",
    "The tree starts at the root, sequentially making comparisons until a decision is made. Think of it as a nested if-statement. The decision node is where the prediction of a class is made. \n",
    "\n",
    "In this reading, we will spend our time on classification trees and a simple implementation of the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture \n",
    "\n",
    "![](https://raw.githubusercontent.com/StevenLoaiza/Machine_Learning/master/Decision%20Trees/image/architecture.PNG)\n",
    "\n",
    "#### Root Node: \n",
    "The first best feature to split the data. The notion of \"best\" will be determined by the splitting criteria used in the decision tree algorithm.\n",
    "\n",
    "#### Leaf Node\n",
    "Based on the feature that was chosen to create the split in the root, the data set will be partitioned into two leaf nodes. For example suppose that the root node said to split on gender, then without loss of generality the left node will hold the set with males and the right node will hold the females.\n",
    "#### Decision Node<a id=\"dec\"></a>\n",
    "After we have made all the possible splits (either on all the features or based on some stopping criteria) a decision must be made as to the target variable. We will discuss the way to choose the 'prediction' made on this node later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data<a id=\"data\"></a>\n",
    "Lets begin by looking at the population data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Emotion Temperature StayHome\n",
      "0     sick        over        N\n",
      "1     sick        over        Y\n",
      "2  notsick        over        Y\n",
      "3  notsick        over        Y\n",
      "4     sick       under        N\n",
      "5  notsick       under        N\n",
      "6  notsick       under        N\n",
      "7     sick       under        Y\n"
     ]
    }
   ],
   "source": [
    "# Create Sample of Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "Emotion=['sick','sick','sick','notsick','notsick','sick','notsick','notsick']\n",
    "Temperature = ['under','over','under','under','over','over','under','over']\n",
    "StayHome=['N','Y','Y','N','Y','N','N','Y']\n",
    "df=pd.DataFrame (list(zip(Emotion,Temperature,StayHome)),\n",
    "                columns=[\"Emotion\",\"Temperature\",\"StayHome\"])\n",
    "print(df.sort_values(['Temperature','StayHome']).reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine that the data above captures 8 individuals and their actions. We would like to create conditional statements in which to split the data in order to make predictions on unobserved decisions to go to work.\n",
    "\n",
    "At the root node, we will split the data set based on the unique values of a given feature. For example, if we used the 'Emotion' feature we would split the data on 'sick' and 'not sick'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>StayHome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>sick</td>\n",
       "      <td>under</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>sick</td>\n",
       "      <td>over</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>sick</td>\n",
       "      <td>over</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>sick</td>\n",
       "      <td>under</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Emotion Temperature StayHome\n",
       "0    sick       under        N\n",
       "5    sick        over        N\n",
       "1    sick        over        Y\n",
       "2    sick       under        Y"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.iloc[:,0]=='sick'].sort_values('StayHome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>StayHome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>notsick</td>\n",
       "      <td>under</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>notsick</td>\n",
       "      <td>under</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>notsick</td>\n",
       "      <td>over</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>notsick</td>\n",
       "      <td>over</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Emotion Temperature StayHome\n",
       "3  notsick       under        N\n",
       "6  notsick       under        N\n",
       "4  notsick        over        Y\n",
       "7  notsick        over        Y"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.iloc[:,0]=='notsick'].sort_values('StayHome')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we used the feature 'Temperature' we woulds split it on 'under' and 'over'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Data on Features<a id=\"splitfeat\"></a>\n",
    "Lets start to code a split of the data based on each unique value of a feature. We will first need the index position of the features, beacuse we will not always have the outcome variable in the last column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Identify the Outcome Variable\n",
    "Outcome='StayHome'\n",
    "#Creates a list of index without the outcome column\n",
    "outcome=df.columns.get_loc(Outcome)\n",
    "col_ls=list(range(len(df.columns)))\n",
    "col_ls.remove(outcome)\n",
    "#print feature positions\n",
    "col_ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will create a copy of the dataset and gather the unique values in a feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have split on feature: ( Emotion ) where it equals ( notsick ) and has 4 observations \n",
      "\n",
      "We have split on feature: ( Emotion ) where it equals ( sick ) and has 4 observations \n",
      "\n"
     ]
    }
   ],
   "source": [
    " #create copy of data and get unique values in each feature\n",
    "new_df=df\n",
    "names,count=np.unique(new_df.iloc[:,col_ls[0]],return_counts=True)\n",
    "# returns how many unique feature there are in this split\n",
    "splitdf=len(names)\n",
    "for i in range(0,len(names)):\n",
    "    print(\"We have split on feature:\",\"(\",new_df.columns[0],\")\",\"where it equals\",\"(\",names[i],\")\",\"and has\",count[i],\"observations \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the code above we have not yet split the data frame. We only have the unique values of the feature and the split count (which will come in handy later on). In order to split the data we will use the index **col_ls** and the unique values **names**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "   Emotion Temperature StayHome\n",
      "3  notsick       under        N\n",
      "4  notsick        over        Y\n",
      "6  notsick       under        N\n",
      "7  notsick        over        Y \n",
      " \n",
      "\n",
      "-----------------------------------------\n",
      "  Emotion Temperature StayHome\n",
      "0    sick       under        N\n",
      "1    sick        over        Y\n",
      "2    sick       under        Y\n",
      "5    sick        over        N \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n in names:\n",
    "    print(\"-----------------------------------------\")\n",
    "    print(new_df[new_df.iloc[:,col_ls[0]]==n],\"\\n\",\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Criteria \n",
    "\n",
    "But how do we choose which feature to split on first?\n",
    "\n",
    "There are two methods we have previously discussed to decide on the best split: [Gini Measure](https://sites.google.com/view/stevenloaiza/machine-learning/decision-trees/gini-impurity-index?authuser=0) and [Information Gain via entropy](https://sites.google.com/view/stevenloaiza/machine-learning/decision-trees/information-gain?authuser=0). We will use the former for the remainder of the discussion.\n",
    "\n",
    "### Gini Measure\n",
    "\n",
    "Recall our definition:\n",
    "\n",
    "Def: Gini Impurity tells us what is the probability of misclassifying an observation, using the distribution from the split, from a random sample conditional on our split.\n",
    "\n",
    "Mathematical definition:\n",
    "\n",
    "$Ginx = \\sum_{n}^{i=1} p_i \\cdot \\sum_{i \\ne j} \\cdot p_i = \\sum_{n}^{i=1} p_i \\cdot (1-p_i)$\n",
    "\n",
    "To generate the gini impurity measure for the entire split we will need to weight them accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain the impurity measure of each split you will need to pass the split data set through the code. It will then evauate the impurity of each **Leaf Node**. Below is an example for one split set, but this would need to be done for all possible splits and then weighted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The gini impurity index is:  0.5 for \n",
      " \n",
      "   Emotion Temperature StayHome\n",
      "0    sick       under        N\n",
      "1    sick        over        N\n",
      "2    sick        over        Y\n",
      "3    sick       under        Y\n"
     ]
    }
   ],
   "source": [
    "splitdata=new_df[new_df.iloc[:,col_ls[0]]==names[1]]\n",
    "# outcome is defined above\n",
    "\n",
    "#gets the unique outcome values\n",
    "value=np.unique(df.iloc[:,outcome])\n",
    "#This will be used later when we computed the weighted gini value\n",
    "denS=len(splitdata)\n",
    "impurity=0\n",
    "                 \n",
    "for values in value:\n",
    "            p=splitdata.iloc[:,outcome].eq(values).sum()/denS\n",
    "            impurity +=p*(1-p)\n",
    "print (\"The gini impurity index is: \",impurity,\"for \\n \\n\", splitdata.sort_values(\"StayHome\").reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the formula above to confirm that the impurity at this split is indeed (0.5). The formula to evaluate is $Gini= (1/2)*(1-1/2)+ (1/2)*(1-1/2)$.\n",
    "\n",
    "Note that the split on \"not sick\" is exactly the same. \n",
    "\n",
    "To get the weighted gini impurity measure we will need to weight each split by its proportion to the data before the split. For instance before the split there were 8 observations, then when we split on \"sick\" and \"not sick\", 4 went to each side respectively.\n",
    "\n",
    "Hence the weighted gini measure is Weighted_Gini= $(4/8)*(0.5)+ (4/8)*(0.5)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weighted gini impurtiy measure is: 0.5\n"
     ]
    }
   ],
   "source": [
    "#create empty list to hold each splits impurity and split count\n",
    "gini_metric=list()\n",
    "den_split=list()\n",
    "        \n",
    "for n in names:\n",
    "    splitdata=new_df[new_df.iloc[:,col_ls[0]]==n]\n",
    "    value=np.unique(df.iloc[:,outcome])\n",
    "#This will be used later when we computed the weighted gini value\n",
    "    denS=len(splitdata)\n",
    "    impurity=0\n",
    "                 \n",
    "    for values in value:\n",
    "            p=splitdata.iloc[:,outcome].eq(values).sum()/denS\n",
    "            impurity +=p*(1-p)\n",
    "    gini_metric.append(impurity)\n",
    "    den_split.append(denS)\n",
    "\n",
    "\n",
    "feature=splitdf\n",
    "# get the proporation of the split for current feature\n",
    "den_split1=[x/sum(den_split[0:feature]) for x in den_split[0:feature]]\n",
    "weighted_gini=sum(np.asarray(den_split1)*np.asarray(gini_metric[0:feature]))\n",
    "\n",
    "print(\"The weighted gini impurtiy measure is:\",weighted_gini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will combine all the code above to iterate over each split of a feature. The empty list \"w_gini\" is keeping track of the weighted gini, then it will return the name of the feature with the lowest weighted gini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generalize our gini Function\n",
    "def Gini(splitdata,outcome):\n",
    "    # Get unique Outcome values\n",
    "    value=np.unique(splitdata.iloc[:,outcome])\n",
    "    denS=len(splitdata)\n",
    "    impurity=0\n",
    "    for values in value:\n",
    "                    p=splitdata.iloc[:,outcome].eq(values).sum()/denS\n",
    "                    impurity +=p*(1-p)\n",
    "    return (impurity,denS)\n",
    "\n",
    "#Tree\n",
    "def SimpleTree(df,Outcome):\n",
    "    if type(Outcome)==str:\n",
    "        \n",
    "         #empty list to hold information\n",
    "        splitdf=list()\n",
    "        gini_metric=list()\n",
    "        w_gini=list()\n",
    "        den_split=list()\n",
    "        split_data=list()\n",
    "        count=0\n",
    "        split_data_index=list()\n",
    "        P=list()\n",
    "        \n",
    "        #Creates a list of index without the outcome column\n",
    "        outcome=df.columns.get_loc(Outcome)\n",
    "        col_ls=list(range(len(df.columns)))\n",
    "        col_ls.remove(outcome)\n",
    "       \n",
    "        #begin loops\n",
    "        for col in col_ls:\n",
    "            #create copy of data and get unique values in each feature\n",
    "            new_df=df\n",
    "            names,count=np.unique(new_df.iloc[:,col],return_counts=True)\n",
    "            #Returns the number of splits per feature \n",
    "            splitdf.append(len(names))\n",
    "            \n",
    "            for n in names:\n",
    "                #returns the columns such that it equals the split criteria\n",
    "                split_df=new_df[new_df.iloc[:,col]==n]\n",
    "                #add df to list\n",
    "                split_data.append(split_df)\n",
    "                #keep track of the columns split data set\n",
    "                index=pd.DataFrame(list([col]))\n",
    "                split_data_index.append(index)\n",
    "     \n",
    "        # Get unique Outcome values\n",
    "        value=np.unique(df.iloc[:,outcome])\n",
    "        \n",
    "        for data in split_data:\n",
    "            #calcualte Gini at each split\n",
    "            impurity,denS=Gini(data,outcome)\n",
    "            #append lists\n",
    "            gini_metric.append(impurity)\n",
    "            den_split.append(denS)\n",
    "        # For loop which will iterate on the number of splits per feature to get the WEIGHTED GINI METRIC\n",
    "        for feature in splitdf:\n",
    "            # get the proporation of the split for current feature\n",
    "            den_split1=[x/sum(den_split[0:feature]) for x in den_split[0:feature]]\n",
    "            weighted_gini=sum(np.asarray(den_split1)*np.asarray(gini_metric[0:feature]))\n",
    "            #remove the gini and feature count split for the next iteration\n",
    "                              \n",
    "            w_gini.append(weighted_gini)\n",
    "            del(gini_metric[0:feature], den_split[0:feature])\n",
    "    else: print(\"Place Outcome Variable Name in \\'Single\\' quotes\")\n",
    "    #return feature with the smallest impurity index\n",
    "    f_col=w_gini.index(min(w_gini))\n",
    "    #returns the name\n",
    "    bestsplit=df.columns[f_col]\n",
    "    return(col_ls,w_gini,split_data,split_data_index,f_col)\n",
    "#------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ( Emotion ) Weighted Gini Impurity Index is: 0.5 \n",
      "\n",
      "Feature ( Temperature ) Weighted Gini Impurity Index is: 0.375 \n",
      "\n",
      "The Best split is with feature ( Temperature )\n"
     ]
    }
   ],
   "source": [
    "col_ls,w_gini,split_data,split_index,bestsplit=SimpleTree(df,\"StayHome\")\n",
    "for col in col_ls:\n",
    "           print(\"Feature\",\"(\",df.columns[col],\")\",\"Weighted Gini Impurity Index is:\", w_gini[col],\"\\n\")\n",
    "print(\"The Best split is with feature\",\"(\",df.columns[bestsplit],\")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsequent Splits <a id=\"moresplit\"></a>\n",
    "\n",
    "Up to this point we have successful decided how to initiate the split from the root node. Our next challenge is to use these data frame after the splits, and perform the same tasks. In other words, once the split occurs on temperature, we do not want to split on temperature again instead the algorithm will use different feature(s) and choose the optimal split.\n",
    "Below we will grab the split data set for the best split column and then remove that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Emotion StayHome\n",
      "1     sick        Y\n",
      "4  notsick        Y\n",
      "5     sick        N\n",
      "7  notsick        Y\n",
      "------------------------\n",
      "   Emotion StayHome\n",
      "0     sick        N\n",
      "2     sick        Y\n",
      "3  notsick        N\n",
      "6  notsick        N\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "# col that holds the index for each column (for instance col 1 (Emotion) has index 1,2 which would help us find the split data)\n",
    "index=pd.DataFrame(split_index)\n",
    "#grab the index for the best split\n",
    "bestsplit_index=list(index[index.iloc[:,0]==bestsplit].index)\n",
    "\n",
    "for n in bestsplit_index:\n",
    "    leaf_data=split_data[n]\n",
    "    leaf_data.drop(leaf_data.columns[bestsplit],axis='columns',inplace=True)\n",
    "    print(leaf_data)\n",
    "    print(\"------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Emotion StayHome\n",
      "4  notsick        Y\n",
      "7  notsick        Y\n",
      "-----------------\n",
      "  Emotion StayHome\n",
      "1    sick        Y\n",
      "5    sick        N\n",
      "-----------------\n",
      "   Emotion StayHome\n",
      "3  notsick        N\n",
      "6  notsick        N\n",
      "-----------------\n",
      "  Emotion StayHome\n",
      "0    sick        N\n",
      "2    sick        Y\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "def addit_leaf(df,Outcome):\n",
    "    #root node split\n",
    "    col_ls,w_gini,split_data,split_index,bestsplit=SimpleTree(df,Outcome)\n",
    "    # Grab the best split and then create the leaf leaf and right leaf split\n",
    "    #hold the resulting datasets\n",
    "    final_data_set=list()\n",
    "    \n",
    "    # col that holds the index for each column (for instance col 1 (Emotion) has index 1,2 which would help us find the split data)\n",
    "    index=pd.DataFrame(split_index)\n",
    "    #grab the index for the best split\n",
    "    bestsplit_index=list(index[index.iloc[:,0]==bestsplit].index)\n",
    "    \n",
    "    # for each split data set re run the simpletree\n",
    "    for n in bestsplit_index:\n",
    "        leaf_data=split_data[n]\n",
    "        leaf_data.drop(leaf_data.columns[bestsplit],axis='columns',inplace=True)\n",
    "        col_ls2,w_gini2,split_data2,split_index2,bestsplit2=SimpleTree(leaf_data,Outcome)\n",
    "        #grab the index for the best split\n",
    "        bestsplit_index=list(index[index.iloc[:,0]==bestsplit2].index)\n",
    "        for i in bestsplit_index:\n",
    "            print(pd.DataFrame(split_data2[i]))\n",
    "            final_data_set.append(pd.DataFrame(split_data2[i]))\n",
    "            print(\"-----------------\")\n",
    "    return(final_data_set,n,bestsplit2)\n",
    "\n",
    "# run the code\n",
    "final_data_set,n,col=addit_leaf(df,\"StayHome\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Code: \n",
    "\n",
    "Lets put it all together.\n",
    "\n",
    "We have made it to the end of the code. Now that all splits have been made, there must be a decision made on the decision node. Specifically, if we were to place some testing data into this Decision Tree model, and it made it all the way down to this decision node, what would the node predict the outcome variable \"StayHome\" to be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction for the decision node  0 is \n",
      "    Target  Prediction Percent\n",
      "0      Y                 1.0 \n",
      "\n",
      "--------------------------------------------------------------\n",
      "The prediction for the decision node  1 is \n",
      "    Target  Prediction Percent\n",
      "0      N                 0.5\n",
      "1      Y                 0.5 \n",
      "\n",
      "--------------------------------------------------------------\n",
      "The prediction for the decision node  2 is \n",
      "    Target  Prediction Percent\n",
      "0      N                 1.0 \n",
      "\n",
      "--------------------------------------------------------------\n",
      "The prediction for the decision node  3 is \n",
      "    Target  Prediction Percent\n",
      "0      N                 0.5\n",
      "1      Y                 0.5 \n",
      "\n",
      "--------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,n+1):\n",
    "    final=pd.DataFrame(final_data_set[i])\n",
    "    final.drop(final.columns[col],axis='columns',inplace=True)\n",
    "    target,count=np.unique(final.iloc[:,0],return_counts=True)\n",
    "    pred_table=pd.DataFrame (list(zip(target,count/sum(count[:]))),\n",
    "                columns=[\"Target\",\"Prediction Percent\"])\n",
    "    print(\"The prediction for the decision node \",i, \"is \\n \",pred_table,\"\\n\")\n",
    "    print(\"--------------------------------------------------------------\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We have complete the decision. Or at least we have compromised 4 different paths that lead to a probabilistic decision. \n",
    "\n",
    "What we have shown is the architecture that leads a decision tree to make a prediction. The next step would be to save the models foundation (how it makes a split and what the decision is in the final splits). This model can then be used on unobserved data, observations without a target variable, to make a prediction. This additional step is out of scope, but the information highlighted above is a concise introduction that helps us grasp the intuition of the method."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "196px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
