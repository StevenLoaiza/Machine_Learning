{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\"><b>Making Decisions with Trees</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction-\" data-toc-modified-id=\"Introduction--1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction <a id=\"intro\"></a></a></span></li><li><span><a href=\"#Architecture-\" data-toc-modified-id=\"Architecture--2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Architecture <a id=\"arc\"></a></a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Root-Node:-\" data-toc-modified-id=\"Root-Node:--2.0.1\"><span class=\"toc-item-num\">2.0.1&nbsp;&nbsp;</span>Root Node: <a id=\"root\"></a></a></span></li><li><span><a href=\"#Leaf-Node\" data-toc-modified-id=\"Leaf-Node-2.0.2\"><span class=\"toc-item-num\">2.0.2&nbsp;&nbsp;</span>Leaf Node<a id=\"leaf\"></a></a></span></li><li><span><a href=\"#Decision-Node\" data-toc-modified-id=\"Decision-Node-2.0.3\"><span class=\"toc-item-num\">2.0.3&nbsp;&nbsp;</span>Decision Node<a id=\"dec\"></a></a></span></li></ul></li></ul></li><li><span><a href=\"#Data\" data-toc-modified-id=\"Data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Data<a id=\"data\"></a></a></span><ul class=\"toc-item\"><li><span><a href=\"#Splitting-Data-on-Features\" data-toc-modified-id=\"Splitting-Data-on-Features-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Splitting Data on Features<a id=\"splitfeat\"></a></a></span></li></ul></li><li><span><a href=\"#Split-Criteria-\" data-toc-modified-id=\"Split-Criteria--4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Split Criteria <a id=\"split\"></a></a></span><ul class=\"toc-item\"><li><span><a href=\"#Gini-Measure\" data-toc-modified-id=\"Gini-Measure-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Gini Measure<a id=\"gini\"></a></a></span></li></ul></li><li><span><a href=\"#Subsequent-Splits-\" data-toc-modified-id=\"Subsequent-Splits--5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Subsequent Splits <a id=\"moresplit\"></a></a></span></li><li><span><a href=\"#Decision-Tree-Code:-\" data-toc-modified-id=\"Decision-Tree-Code:--6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Decision Tree Code: <a id=\"tree\"></a></a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction <a id=\"intro\"></a>\n",
    "\n",
    "Decision trees are a simple yet powerful tool in predictive modeling. \n",
    "\n",
    "Unlike other predictive models, such as neural networks, we are able to decipher the inner working of a decision trees. In other words, they are easier to interpret. We can trace back the decisions that led to a particular prediction.\n",
    "\n",
    "The tree starts at the root, sequentially making comparisons until a decision is made. Think of it as a nested if statement. The decision node is where the prediction of a class is made. \n",
    "\n",
    "In this reading, we will spend our time on classification trees and a simple implementaton of the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture <a id=\"arc\"></a>\n",
    "\n",
    "![](architecture.png)\n",
    "\n",
    "#### Root Node: <a id=\"root\"></a>\n",
    "The first best feature to split the data. The notion of \"best\" will be determined by the splitting criteria used in the decision tree algorithm.\n",
    "\n",
    "#### Leaf Node<a id=\"leaf\"></a>\n",
    "\n",
    "#### Decision Node<a id=\"dec\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data<a id=\"data\"></a>\n",
    "Lets begin by looking at the population data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Emotion Temperature StayHome\n",
      "0     sick        over        N\n",
      "1     sick        over        Y\n",
      "2  notsick        over        Y\n",
      "3  notsick        over        Y\n",
      "4     sick       under        N\n",
      "5  notsick       under        N\n",
      "6  notsick       under        N\n",
      "7     sick       under        Y\n"
     ]
    }
   ],
   "source": [
    "# Create Sample of Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "Emotion=['sick','sick','sick','notsick','notsick','sick','notsick','notsick']\n",
    "Temperature = ['under','over','under','under','over','over','under','over']\n",
    "StayHome=['N','Y','Y','N','Y','N','N','Y']\n",
    "df=pd.DataFrame (list(zip(Emotion,Temperature,StayHome)),\n",
    "                columns=[\"Emotion\",\"Temperature\",\"StayHome\"])\n",
    "print(df.sort_values(['Temperature','StayHome']).reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make decisions in our lives everyday. Although we make decisions so often, we may not stop to think exactly how we made them.\n",
    "\n",
    "Let's think about a decision many of us have come across: **Going to Work**. Without realizing it, we tend to ask ourselves sequential questions, that lead us to our decision.\n",
    "\n",
    "Imagine that the data above captures 8 individuals and their actions. We would like to create conditional statements in which to split the data in order to make predictions on unobserved decisions to go to work.\n",
    "\n",
    "At the root node, we will split the data set based on the unique values of a given feature. For example, if we used the 'Emotion' feature we would split the data on 'sick' and 'not sick'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>StayHome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sick</td>\n",
       "      <td>under</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sick</td>\n",
       "      <td>over</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sick</td>\n",
       "      <td>over</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sick</td>\n",
       "      <td>under</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Emotion Temperature StayHome\n",
       "0    sick       under        N\n",
       "5    sick        over        N\n",
       "1    sick        over        Y\n",
       "2    sick       under        Y"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.iloc[:,0]=='sick'].sort_values('StayHome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>StayHome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>notsick</td>\n",
       "      <td>under</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>notsick</td>\n",
       "      <td>under</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>notsick</td>\n",
       "      <td>over</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>notsick</td>\n",
       "      <td>over</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Emotion Temperature StayHome\n",
       "3  notsick       under        N\n",
       "6  notsick       under        N\n",
       "4  notsick        over        Y\n",
       "7  notsick        over        Y"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.iloc[:,0]=='notsick'].sort_values('StayHome')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we used the feature 'Temperature' we wouls split it on 'under' and 'over'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Data on Features<a id=\"splitfeat\"></a>\n",
    "Lets start to code a split of the data based on each unique value of a feature. We will first need the index position of the features, beacuse we will not always have the outcome variable in the last column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Identify the Outcome Variable\n",
    "Outcome='StayHome'\n",
    "#Creates a list of index without the outcome column\n",
    "outcome=df.columns.get_loc(Outcome)\n",
    "col_ls=list(range(len(df.columns)))\n",
    "col_ls.remove(outcome)\n",
    "#print feature positions\n",
    "col_ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will create a copy of the dataset and gather the unique values in a feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have split on feature: ( Emotion ) where it equals ( notsick ) and has 4 observations \n",
      "\n",
      "We have split on feature: ( Emotion ) where it equals ( sick ) and has 4 observations \n",
      "\n"
     ]
    }
   ],
   "source": [
    " #create copy of data and get unique values in each feature\n",
    "new_df=df\n",
    "names,count=np.unique(new_df.iloc[:,col_ls[0]],return_counts=True)\n",
    "# returns how many unique feature there are in this split\n",
    "splitdf=len(names)\n",
    "for i in range(0,len(names)):\n",
    "    print(\"We have split on feature:\",\"(\",new_df.columns[0],\")\",\"where it equals\",\"(\",names[i],\")\",\"and has\",count[i],\"observations \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the code above we have not yet split the data frame. We only have the unique values of the feature and the split count (which will come in handy later on). In order to split the data we will use the index **col_ls** and the unique values **names**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "   Emotion Temperature StayHome\n",
      "3  notsick       under        N\n",
      "4  notsick        over        Y\n",
      "6  notsick       under        N\n",
      "7  notsick        over        Y \n",
      " \n",
      "\n",
      "-----------------------------------------\n",
      "  Emotion Temperature StayHome\n",
      "0    sick       under        N\n",
      "1    sick        over        Y\n",
      "2    sick       under        Y\n",
      "5    sick        over        N \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n in names:\n",
    "    print(\"-----------------------------------------\")\n",
    "    print(new_df[new_df.iloc[:,col_ls[0]]==n],\"\\n\",\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Criteria <a id=\"split\"></a>\n",
    "\n",
    "But how do we choose which feature to split on first?\n",
    "\n",
    "There are two methods we have previously discussed to decide on the best split: [Gini Measure](https://sites.google.com/view/stevenloaiza/machine-learning/decision-trees/gini-impurity-index?authuser=0) and [Information Gain via entropy](https://sites.google.com/view/stevenloaiza/machine-learning/decision-trees/information-gain?authuser=0). We will use the former for the remainder of the discussion.\n",
    "\n",
    "### Gini Measure<a id=\"gini\"></a>\n",
    "\n",
    "Recall our definition:\n",
    "\n",
    "Def: Gini Impurity tells us what is the probability of misclassifying an observation, using the distribution from the split, from a random sample conditional on our split.\n",
    "\n",
    "Mathematical definition:\n",
    "\n",
    "$Ginx = \\sum_{n}^{i=1} p_i \\cdot \\sum_{i \\ne j} \\cdot p_i = \\sum_{n}^{i=1} p_i \\cdot (1-p_i)$\n",
    "\n",
    "To generate the gini impurity measure for the entire split we will need to weight them accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain the impurity measure of each split you will need to pass the split data set through the code. It will then evauate the impurity of each **Leaf Node**. Below is an example for one split set, but this would need to be done for all possible splits and then weighted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The gini impurity index is:  0.5 for \n",
      " \n",
      "   Emotion Temperature StayHome\n",
      "0    sick       under        N\n",
      "1    sick        over        N\n",
      "2    sick        over        Y\n",
      "3    sick       under        Y\n"
     ]
    }
   ],
   "source": [
    "splitdata=new_df[new_df.iloc[:,col_ls[0]]==names[1]]\n",
    "# outcome is defined above\n",
    "\n",
    "#gets the unique outcome values\n",
    "value=np.unique(df.iloc[:,outcome])\n",
    "#This will be used later when we computed the weighted gini value\n",
    "denS=len(splitdata)\n",
    "impurity=0\n",
    "                 \n",
    "for values in value:\n",
    "            p=splitdata.iloc[:,outcome].eq(values).sum()/denS\n",
    "            impurity +=p*(1-p)\n",
    "print (\"The gini impurity index is: \",impurity,\"for \\n \\n\", splitdata.sort_values(\"StayHome\").reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the formula above to confirm that the impurity at this split is indeed (0.5). The formula to evaluate is $Gini= (1/2)*(1-1/2)+ (1/2)*(1-1/2)$.\n",
    "\n",
    "Note that the split on \"not sick\" is exactly the same. \n",
    "\n",
    "To get the weighted gini impurity measure we will need to weight each split by its proportion to the data before the split. For instance before the split there were 8 observations, then when we split on \"sick\" and \"not sick\", 4 went bto each side respectively.\n",
    "\n",
    "Hence the weighted gini measure is Weighted_Gini= $(4/8)*(0.5)+ (4/8)*(0.5)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weighted gini impurtiy measure is: 0.5\n"
     ]
    }
   ],
   "source": [
    "#create empty list to hold each splits impurity and split count\n",
    "gini_metric=list()\n",
    "den_split=list()\n",
    "        \n",
    "for n in names:\n",
    "    splitdata=new_df[new_df.iloc[:,col_ls[0]]==n]\n",
    "    value=np.unique(df.iloc[:,outcome])\n",
    "#This will be used later when we computed the weighted gini value\n",
    "    denS=len(splitdata)\n",
    "    impurity=0\n",
    "                 \n",
    "    for values in value:\n",
    "            p=splitdata.iloc[:,outcome].eq(values).sum()/denS\n",
    "            impurity +=p*(1-p)\n",
    "    gini_metric.append(impurity)\n",
    "    den_split.append(denS)\n",
    "\n",
    "\n",
    "feature=splitdf\n",
    "# get the proporation of the split for current feature\n",
    "den_split1=[x/sum(den_split[0:feature]) for x in den_split[0:feature]]\n",
    "weighted_gini=sum(np.asarray(den_split1)*np.asarray(gini_metric[0:feature]))\n",
    "\n",
    "print(\"The weighted gini impurtiy measure is:\",weighted_gini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will combine all the code above to iterate over each split of a feature. The empty list \"w_gini\" is keeping track of the weighted gini, then it will return the name of the feature with the lowest weighted gini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generalize our gini Function\n",
    "def Gini(splitdata,outcome):\n",
    "    # Get unique Outcome values\n",
    "    value=np.unique(df.iloc[:,outcome])\n",
    "    denS=len(splitdata)\n",
    "    impurity=0\n",
    "    for values in value:\n",
    "                    p=splitdata.iloc[:,outcome].eq(values).sum()/denS\n",
    "                    impurity +=p*(1-p)\n",
    "    return (impurity,denS)\n",
    "\n",
    "#Tree\n",
    "def SimpleTree(df,Outcome):\n",
    "    if type(Outcome)==str:\n",
    "        \n",
    "         #empty list to hold information\n",
    "        splitdf=list()\n",
    "        gini_metric=list()\n",
    "        w_gini=list()\n",
    "        den_split=list()\n",
    "        split_data=list()\n",
    "        P=list()\n",
    "        \n",
    "        #Creates a list of index without the outcome column\n",
    "        outcome=df.columns.get_loc(Outcome)\n",
    "        col_ls=list(range(len(df.columns)))\n",
    "        col_ls.remove(outcome)\n",
    "       \n",
    "        #begin loops\n",
    "        for col in col_ls:\n",
    "            #create copy of data and get unique values in each feature\n",
    "            new_df=df\n",
    "            names,count=np.unique(new_df.iloc[:,col],return_counts=True)\n",
    "            #Returns the number of splits per feature \n",
    "            splitdf.append(len(names))\n",
    "            \n",
    "            for n in names:\n",
    "                #returns the columns such that it equals the split criteria\n",
    "                split_df=new_df[new_df.iloc[:,col]==n]\n",
    "                #add df to list\n",
    "                \n",
    "                split_data.append(split_df)\n",
    "                \n",
    "        # Get unique Outcome values\n",
    "        value=np.unique(df.iloc[:,outcome])\n",
    "        \n",
    "        for data in split_data:\n",
    "            #calcualte Gini at each split\n",
    "            impurity,denS=Gini(data,outcome)\n",
    "            #append lists\n",
    "            gini_metric.append(impurity)\n",
    "            den_split.append(denS)\n",
    "        # For loop which will iterate on the number of splits per feature to get the WEIGHTED GINI METRIC\n",
    "        for feature in splitdf:\n",
    "            # get the proporation of the split for current feature\n",
    "            den_split1=[x/sum(den_split[0:feature]) for x in den_split[0:feature]]\n",
    "            weighted_gini=sum(np.asarray(den_split1)*np.asarray(gini_metric[0:feature]))\n",
    "            #remove the gini and feature count split for the next iteration\n",
    "                              \n",
    "            w_gini.append(weighted_gini)\n",
    "            del(gini_metric[0:feature], den_split[0:feature])\n",
    "    else: print(\"Place Outcome Variable Name in \\'Single\\' quotes\")\n",
    "    #return feature with the smallest impurity index\n",
    "    f_col=w_gini.index(min(w_gini))\n",
    "    #returns the name\n",
    "    bestsplit=df.columns[f_col]\n",
    "    return(col_ls,w_gini,bestsplit,split_data)\n",
    "#------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ( Emotion ) Weighted Gini Impurity Index is: 0.5 \n",
      "\n",
      "Feature ( Temperature ) Weighted Gini Impurity Index is: 0.375 \n",
      "\n",
      "The Best split is with feature ( Temperature )\n"
     ]
    }
   ],
   "source": [
    "col_ls,w_gini,bestsplit,k=SimpleTree(df,\"StayHome\")\n",
    "for col in col_ls:\n",
    "           print(\"Feature\",\"(\",df.columns[col],\")\",\"Weighted Gini Impurity Index is:\", w_gini[col],\"\\n\")\n",
    "print(\"The Best split is with feature\",\"(\",bestsplit,\")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsequent Splits <a id=\"moresplit\"></a>\n",
    "\n",
    "Up to this point we have successful decided how to initiate the split from the root node. Our next challenge is to use these data frame after the splits, and perfrom the same tasks. In other words, once the split occurs on temperature, we do not want to split on temperature again instead the algorithm will use different feature(s) and choose the optimal split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Code: <a id=\"tree\"></a>\n",
    "\n",
    "Lets put it all together now."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "196px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
